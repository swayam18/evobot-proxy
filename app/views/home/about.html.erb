<div class="jumbotron">
  <div class="container">
    <h1> Artifical Life </h1>
    <p></p>
    <p>Robots at Work, Sleep, Play.</p>
  </div>
</div>
<div class="container">
  <div class="row">
    <div class="page-header">
    <h1> About 
    <small> Artificial Life </p>
    </h1>
    </div>
    <p>
    The goal of the Artificial Life project is to design a real-world testing platform to examine 
evolutionary learning control algorithms which are
    </p>
    <ul>
      <li>
        flexible enough to help examine machine learning for various sensors, in various
        environments and for various applications,
      </li>
      <li>
         cheap enough to be able to be replicated globally and connected to a common scalable
        learning platform,
      </li>
      <li>
         simple enough to operate in sub-optimal environments with field-repairs and to be 
        quickly learned and understood by pre-university students. 
      </li>
    </ul>
    <p>
    The first generation of EvoBots are two-wheeled Android phone- controlled vehicles with solar 
    panels to recharge their batteries shown in the Art Science exhibition. The robot’s brains, while 
    hosted on a server, are unique to each individual. Successful individuals pass ‘good’ survival 
    strategies genetically on to their offspring, and generations learn how to ‘feed’ themselves from 
    solar energy while avoiding dangers from predators, finding prey and performing other flexible
    tasks.
    </p>

    <div class="page-header">
    <h1> Presentation 
    <small> at the Art Science Museum</small>
    </h1>

    <p>
The salient features of the EvoBots platform which demonstrate artificial life are:
    </p>
    <ul>
      <li>
      They have been developed over the course of the past 2 years starting at MIT and were 
supported by the SUTD International Design Center
      </li>
      <li>
      They are 3-D printed, and cost roughly 20 SGD (not including the Android smartphone)
      </li>
      <li>
      They will work with almost all smartphones (in case visitors wish to purchase them, they 
are available at www.edgebotix.com
      </li>
      <li>
      They are currently running an evolutionary task called the ‘predator/prey’ simulation 
where
<ul>
      <li>
One robot is the prey, and tries to escape the predator. The prey can move faster 
than the predator
      </li>
      <li>
The other robot is the predator, and tries to catch the prey. The predator moves 
slower, but can see farther than the prey
      </li>
</ul>
      </li>
      <li>
      This is a live experiment, and data is being used to explore the concept of artificial life.
      </li>
    </ul>
    <div class="page-header">
    <h1> People 
    <small> behind Artificial Life</small>
    </h1>
    <p>
      This project is brought to you by Swayam Narain, Wen Zheng Li and Erik Wilhelm
    </p>
    </div>
  </div>
</div>
